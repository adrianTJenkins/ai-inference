name: 'AI Inference'
description: Generate an AI response based on a provided prompt
author: 'GitHub'

# Add your action's branding here. This will appear on the GitHub Marketplace.
branding:
  icon: 'message-square'
  color: red

# Define your inputs here.
inputs:
  prompt:
    description: The prompt for the model
    required: false
    default: ''
  prompt-file:
    description: Path to a file containing the prompt (supports .txt and .prompt.yml
      formats)
    required: false
    default: ''
  input:
    description: Template variables in YAML format for .prompt.yml files
    required: false
    default: ''
  file_input:
    description: Template variables in YAML format mapping variable names to file paths. The file contents will be used for templating.
    required: false
    default: ''
  model:
    description: The model to use
    required: false
    default: 'openai/gpt-4o'
  endpoint:
    description: The endpoint to use
    required: false
    default: 'https://models.github.ai/inference'
  system-prompt:
    description: The system prompt for the model
    required: false
    default: 'You are a helpful assistant'
  system-prompt-file:
    description: Path to a file containing the system prompt
    required: false
    default: ''
  max-tokens:
    description: The maximum number of tokens to generate
    required: false
    default: '200'
  token:
    description: The token to use
    required: false
    default: ${{ github.token }}
  enable-github-mcp:
    description: Enable Model Context Protocol integration (legacy alias for enable-mcp)
    required: false
    default: 'false'
  enable-mcp:
    description: Enable Model Context Protocol integration (requires .github/.mcp.json configuration file)
    required: false
    default: 'false'
  mcp-config-path:
    description: Path to MCP configuration file (defaults to .github/.mcp.json)
    required: false
    default: ''
  github-mcp-token:
    description: '[DEPRECATED] Use environment variables in .mcp.json instead. The token to use for GitHub MCP server.'
    required: false
    default: ''
    deprecationMessage: 'Use .mcp.json configuration file with environment variables instead'
  sentry-token:
    description: '[DEPRECATED] Use environment variables in .mcp.json instead. The token to use for Sentry MCP server.'
    required: false
    default: ''
    deprecationMessage: 'Use .mcp.json configuration file with environment variables instead'
  datadog-api-key:
    description: '[DEPRECATED] Use environment variables in .mcp.json instead. The API key to use for Datadog MCP server.'
    required: false
    default: ''
    deprecationMessage: 'Use .mcp.json configuration file with environment variables instead'
  datadog-app-key:
    description: '[DEPRECATED] Use environment variables in .mcp.json instead. The application key to use for Datadog MCP server.'
    required: false
    default: ''
    deprecationMessage: 'Use .mcp.json configuration file with environment variables instead'
  azure-client-id:
    description: '[DEPRECATED] Use environment variables in .mcp.json instead. The client ID for Azure Service Principal authentication.'
    required: false
    default: ''
    deprecationMessage: 'Use .mcp.json configuration file with environment variables instead'
  azure-client-secret:
    description: '[DEPRECATED] Use environment variables in .mcp.json instead. The client secret for Azure Service Principal authentication.'
    required: false
    default: ''
    deprecationMessage: 'Use .mcp.json configuration file with environment variables instead'
  azure-tenant-id:
    description: '[DEPRECATED] Use environment variables in .mcp.json instead. The tenant ID for Azure Service Principal authentication.'
    required: false
    default: ''
    deprecationMessage: 'Use .mcp.json configuration file with environment variables instead'

# Define your outputs here.
outputs:
  response:
    description: The response from the model
  response-file:
    description: The file path where the response is saved

runs:
  using: node24
  main: dist/index.js
